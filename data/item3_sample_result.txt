True	Adversative	Adversative	An example is ‘yaf’aloun’ (i.e., they do), where ‘ya’ and ‘oun’ are non-essential.	the attached pronouns, the algorithm does not perform pattern matching to detect whether a verb belongs to the five common verbs.
True	Causal	Causal	The drawback to the use of a relatively large number of questions was that some questions were answered by as few as 2 users or as many as 24 users.	the known difficulty of assessing the output of question–answering and IR systems, we devoted considerable effort to identifying correct answers and to developing procedures to reliably compare term effectiveness.
True	Adversative	Adversative	Linguistically, such “closely” related words could be synonyms, near-synonyms, abbreviations, alternate spelling forms, and in some cases hyponyms, co-hyponyms and hypernyms.	it is possible to implement sophisticated methods relying on machine-readable dictionaries and thesauri, we opted to use a much simpler method at this stage: if two or more concepts in the query have at least one word in common, they are considered to belong to one facet.
True	Causal	Causal	However, it overestimates topic shifts, ignoring the statistical characteristics of consecutive queries.	it performes worse than previous methods.
True	Additive	Additive	Alternative input methods for specifying a query that can replace the common, but challenging, keyword query input using a keyboard were studied.	Jansen, Bos, van der Vet, Huibers, and Hiemstra (2010) proposed a tangible interface called TeddIR.
True	Causal	Causal	This can be seen in Fig. 3, which shows the distribution for the DGap values for different document orders.	the ordered case generates many 0 DGaps (Ding, Attenberg, & Suel, 2010).
False	Causal	Adversative	Table 2 provides a summary of kinematic compression performace using the low-speed segmentation technique.	a development effort is needed in order to deploy this technique on the browser.
True	Sequential	Sequential	Although existing studies have provided much knowledge about the relationship between user characteristics and SNS content, some limitations still remain.	the majority of relevant studies primarily examined text content, less so photo/image content.
False	Causal	Additive	The main limitation of the supervised method is to label a huge amount of data to train the model, which is laborious and time-consuming.	in search of an alternative to the supervised method, semi-supervised methods learn domain knowledge from a small set of labeled data on top of a pre-trained unsupervised model.
True	Causal	Causal	The results show that NB consistently outperforms SVM and ME and representing document vectors by binary features (word presence and absence) gives better results than using TFIDF features.	we only report results from NB trained on document vectors with binary features.
